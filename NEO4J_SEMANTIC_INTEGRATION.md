# Neo4j Data Schema and Production Interface

## Purpose

This document defines what the chirality-semantic-framework produces and how it structures data for Neo4j persistence. The backend is responsible for creating, transforming, and persisting semantic components with complete operational audit trails.

## Data Schema We Produce

### Node Types Created by Backend

#### 1. Component Nodes
```cypher
// What we produce for each semantic component
(:Component {
    id: "thread:matrix:row:col",           // Generated by backend
    matrix_name: "A|B|C|D|F|J",            // Set during creation
    matrix_position: [row, col],           // Computed from operations
    thread_id: "operation_context",        // Assigned at creation
    initial_content: "raw_value",          // Original cell value
    current_state: "initial|interpreted|combined|resolved",  // Tracked by backend
    semantic_domain: "software_dev",       // Set by operation context
    ontology_binding: "cf14:domain:matrix:row:col:hash",  // Generated
    created_at: datetime(),                // Set on creation
    updated_at: datetime()                 // Updated on state change
})
```

#### 2. ComponentState Nodes  
```cypher
// State snapshots we produce during transformations
(:ComponentState {
    id: "generated_uuid",                  // Backend generates
    component_id: "parent_component",      // Link to component
    state_type: "interpreted",             // State in lifecycle
    content: "semantic_result",            // Transformation output
    timestamp: datetime(),                 // When produced
    operation_metadata: {                  // Operation context
        operation: "semantic_multiplication",
        resolver: "openai_gpt4",
        sources: ["comp_a", "comp_b"]
    }
})
```

#### 3. SemanticOperation Nodes
```cypher
// Operation records we create for audit trails
(:SemanticOperation {
    id: "operation_uuid",                  // Backend generates
    operation_type: "multiplication|addition|truncation",  // What we did
    resolver: "openai|claude|demo",        // How we did it
    timestamp: datetime(),                 // When we did it
    input_components: ["id1", "id2"],      // What we operated on
    output_component: "result_id",         // What we produced
    performance_metrics: {                 // How it performed
        duration_ms: 1250,
        api_calls: 1,
        tokens_used: 350
    }
})
```

#### 4. SemanticThread Nodes
```cypher
// Thread context we maintain for operation sequences
(:SemanticThread {
    id: "thread_identifier",               // Backend assigns
    domain: "problem_domain",              // Context for operations
    creation_time: datetime(),             // Thread start
    component_count: 16,                   // Components in thread
    operation_count: 12,                   // Operations performed
    current_station: "requirements",       // CF14 station tracking
    metadata: {...}                        // Additional context
})
```

### Relationships We Create

```cypher
// Component state evolution - created during state transitions
(:Component)-[:HAS_STATE {sequence: 1, is_current: true}]->(:ComponentState)

// Operation lineage - created after operations complete
(:SemanticOperation)-[:PRODUCES {role: "output"}]->(:Component)
(:SemanticOperation)-[:CONSUMES {role: "input", index: 0}]->(:Component)

// Component dependencies - derived from operations
(:Component)-[:DEPENDS_ON {operation_type: "semantic_multiplication"}]->(:Component)

// Thread membership - assigned at component creation
(:SemanticThread)-[:CONTAINS {position: [0,0]}]->(:Component)

// Semantic derivation - high-level operation tracking
(:Component)-[:DERIVES_FROM {operation: "A*B=C"}]->(:Component)
```

## Backend Production Interface

### Task 1: Component Production Methods

**What We Implement**:
```python
class ComponentProducer:
    def produce_initial_component(self, matrix_name: str, position: Tuple[int, int], 
                                 content: str, thread_id: str) -> Dict:
        """
        Produces initial component data for Neo4j.
        Returns: Component dict ready for Neo4j persistence
        """
        component = {
            "id": f"{thread_id}:{matrix_name}:{position[0]}:{position[1]}",
            "matrix_name": matrix_name,
            "matrix_position": list(position),
            "thread_id": thread_id,
            "initial_content": content,
            "current_state": "initial",
            "semantic_domain": self.get_domain(thread_id),
            "ontology_binding": self.generate_address(matrix_name, position),
            "created_at": datetime.utcnow().isoformat()
        }
        return component
    
    def produce_state_transition(self, component_id: str, new_state: str, 
                                content: str, operation: Dict) -> Dict:
        """
        Produces state transition data for Neo4j.
        Returns: State transition dict for persistence
        """
        return {
            "component_id": component_id,
            "state_type": new_state,
            "content": content,
            "timestamp": datetime.utcnow().isoformat(),
            "operation_metadata": operation
        }
```

### Task 2: Operation Audit Production

**What We Generate**:
```python
class OperationAuditProducer:
    def produce_operation_audit(self, operation_type: str, inputs: List[str], 
                               output: str, resolver: str, metrics: Dict) -> Dict:
        """
        Produces operation audit record for Neo4j.
        Returns: Operation audit dict for persistence
        """
        return {
            "id": str(uuid.uuid4()),
            "operation_type": operation_type,
            "resolver": resolver,
            "timestamp": datetime.utcnow().isoformat(),
            "input_components": inputs,
            "output_component": output,
            "performance_metrics": metrics
        }
    
    def produce_lineage_relationships(self, operation_id: str, 
                                     inputs: List[str], output: str) -> List[Dict]:
        """
        Produces relationship data for operation lineage.
        Returns: List of relationship dicts for Neo4j
        """
        relationships = []
        
        # Output relationship
        relationships.append({
            "from": operation_id,
            "to": output,
            "type": "PRODUCES",
            "properties": {"role": "output"}
        })
        
        # Input relationships
        for idx, input_id in enumerate(inputs):
            relationships.append({
                "from": operation_id,
                "to": input_id,
                "type": "CONSUMES",
                "properties": {"role": "input", "index": idx}
            })
        
        return relationships
```

### Task 3: Batch Production Interface

**Batch Processing We Provide**:
```python
class BatchProducer:
    def produce_matrix_components(self, matrix: Matrix, thread_id: str) -> List[Dict]:
        """
        Produces all components for a matrix.
        Returns: List of component dicts for batch persistence
        """
        components = []
        for row in range(matrix.rows):
            for col in range(matrix.cols):
                component = self.component_producer.produce_initial_component(
                    matrix_name=matrix.name,
                    position=(row, col),
                    content=matrix.get_cell(row, col),
                    thread_id=thread_id
                )
                components.append(component)
        return components
    
    def produce_operation_batch(self, operations: List[SemanticOperation]) -> Dict:
        """
        Produces batch of operations with all relationships.
        Returns: Dict with nodes and relationships for batch persistence
        """
        return {
            "operation_nodes": [self.produce_operation_audit(op) for op in operations],
            "relationships": [rel for op in operations 
                            for rel in self.produce_lineage_relationships(op)],
            "state_updates": [self.produce_state_transition(op) for op in operations]
        }
```

### Task 4: Semantic Address Generation

**Address Production Logic**:
```python
class SemanticAddressProducer:
    def produce_cell_address(self, domain: str, matrix: str, 
                            row: int, col: int) -> str:
        """
        Produces unique semantic address for a cell.
        Returns: cf14 format address string
        """
        content_hash = self.compute_content_hash(domain, matrix, row, col)
        return f"cf14:{domain}:{matrix}:{row}:{col}:{content_hash[:8]}"
    
    def produce_address_index(self, components: List[Dict]) -> Dict[str, str]:
        """
        Produces address index for component lookup.
        Returns: Mapping of component IDs to semantic addresses
        """
        return {
            comp["id"]: self.produce_cell_address(
                comp["semantic_domain"],
                comp["matrix_name"],
                comp["matrix_position"][0],
                comp["matrix_position"][1]
            )
            for comp in components
        }
```

## Data Production Pipeline

### Task 5: Production Workflow

**Our Production Sequence**:
```python
class SemanticProductionPipeline:
    def produce_semantic_operation(self, operation_type: str, inputs: List) -> Dict:
        """
        Complete production pipeline for semantic operations.
        """
        # 1. Create operation context
        thread_id = self.create_or_get_thread()
        
        # 2. Produce initial components
        input_components = self.produce_input_components(inputs, thread_id)
        
        # 3. Execute semantic operation (LLM call)
        result = self.execute_operation(operation_type, input_components)
        
        # 4. Produce output components
        output_components = self.produce_output_components(result, thread_id)
        
        # 5. Produce operation audit
        operation_audit = self.produce_operation_audit(
            operation_type, input_components, output_components
        )
        
        # 6. Produce state transitions
        state_transitions = self.produce_state_transitions(
            output_components, operation_audit
        )
        
        # 7. Package for Neo4j
        return {
            "components": output_components,
            "operations": [operation_audit],
            "states": state_transitions,
            "relationships": self.produce_relationships(operation_audit)
        }
```

### Task 6: Data Validation Before Production

**Validation We Perform**:
```python
class ProductionValidator:
    def validate_before_production(self, data: Dict) -> bool:
        """
        Validates data before sending to Neo4j.
        """
        validations = [
            self.validate_component_structure(data.get("components", [])),
            self.validate_operation_completeness(data.get("operations", [])),
            self.validate_state_sequence(data.get("states", [])),
            self.validate_relationship_integrity(data.get("relationships", []))
        ]
        return all(validations)
    
    def validate_component_structure(self, components: List[Dict]) -> bool:
        """
        Ensures components have required fields.
        """
        required_fields = ["id", "matrix_name", "matrix_position", 
                          "thread_id", "initial_content", "current_state"]
        
        for component in components:
            if not all(field in component for field in required_fields):
                return False
        return True
```

## Production Metrics and Monitoring

### Task 7: Production Telemetry

**Metrics We Emit**:
```python
class ProductionTelemetry:
    def record_production_metrics(self, operation: str, data: Dict):
        """
        Records what we produce for monitoring.
        """
        metrics = {
            "operation_type": operation,
            "components_produced": len(data.get("components", [])),
            "operations_created": len(data.get("operations", [])),
            "states_recorded": len(data.get("states", [])),
            "relationships_established": len(data.get("relationships", [])),
            "timestamp": datetime.utcnow().isoformat()
        }
        
        # Send to monitoring system
        self.metrics_collector.record(metrics)
        
        return metrics
```

## Error Handling in Production

### Task 8: Production Error Management

**How We Handle Production Failures**:
```python
class ProductionErrorHandler:
    def handle_production_failure(self, data: Dict, error: Exception):
        """
        Handles failures in data production.
        """
        # 1. Log the failure
        self.logger.error(f"Production failed: {error}", extra={"data": data})
        
        # 2. Store in recovery queue
        self.recovery_queue.add({
            "data": data,
            "error": str(error),
            "timestamp": datetime.utcnow().isoformat(),
            "retry_count": 0
        })
        
        # 3. Emit failure metric
        self.metrics.increment("production_failures", tags={"operation": data.get("type")})
        
        # 4. Return partial success if possible
        return self.attempt_partial_production(data)
```

## Testing Our Production

### Task 9: Production Testing

**Tests for Data Production**:
```python
class TestDataProduction:
    def test_component_production(self):
        """Test we produce valid components."""
        producer = ComponentProducer()
        component = producer.produce_initial_component(
            matrix_name="A",
            position=(0, 0),
            content="Quality",
            thread_id="test_thread"
        )
        
        assert component["id"] == "test_thread:A:0:0"
        assert component["current_state"] == "initial"
        assert "ontology_binding" in component
    
    def test_operation_audit_production(self):
        """Test we produce complete operation audits."""
        producer = OperationAuditProducer()
        audit = producer.produce_operation_audit(
            operation_type="semantic_multiplication",
            inputs=["comp1", "comp2"],
            output="comp3",
            resolver="openai_gpt4",
            metrics={"duration_ms": 1000}
        )
        
        assert audit["operation_type"] == "semantic_multiplication"
        assert len(audit["input_components"]) == 2
        assert audit["performance_metrics"]["duration_ms"] == 1000
```

## Summary

This backend-focused document defines exactly what the chirality-semantic-framework produces for Neo4j consumption. We are responsible for:

1. **Producing** semantic components with complete state history
2. **Generating** operation audit trails with performance metrics  
3. **Creating** semantic addresses for cell-based memory
4. **Establishing** relationships between components and operations
5. **Validating** all data before persistence
6. **Monitoring** production health and performance
7. **Handling** production failures gracefully

The frontend can consume this data via GraphQL without needing to understand how it's produced.